<!--
Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)
-->
<!DOCTYPE html>
<html>
  <head>
    <script src="https://sdk.amazonaws.com/js/aws-sdk-2.16.0.min.js"></script>
    <meta charset="UTF-8" />
    <title>Rekognition</title>
  </head>

  <body>
    <h1>Rekognition Demo</h1>
    <input type="file" name="fileToUpload" id="fileToUpload" accept="image/*" />
  </body>
  <script>
    document.getElementById("fileToUpload").addEventListener(
      "change",
      function (event) {
        ProcessImage("fileToUpload");
      },
      false
    );

    async function getFaceInfo(imageData) {
      AWS.config.region = "ap-northeast-2"; // 리전
      AWS.config.credentials = new AWS.CognitoIdentityCredentials({
        IdentityPoolId: "ap-northeast-2:1ea17bad-714a-4e6e-9fee-e4203f40ebb4",
      });
      // Make the call to obtain credentials
      AWS.config.credentials.get();

      const rekognition = new AWS.Rekognition();
      const params = {
        Image: {
          Bytes: imageData,
        },
        Attributes: ["ALL"],
      };

      return new Promise((resolve, reject) => {
        rekognition.detectFaces(params, (err, data) => {
          if (err) {
            reject(err);
          }

          const faceInfo = data.FaceDetails[0];

          const result = {
            face: {
              width: faceInfo["BoundingBox"]["Width"],
              height: faceInfo["BoundingBox"]["Height"],
              top: faceInfo["BoundingBox"]["Top"],
              left: faceInfo["BoundingBox"]["Left"],
            },
            mask: {
              width: faceInfo["BoundingBox"]["Width"],
              height: faceInfo["BoundingBox"]["Height"] / 3,
              top:
                faceInfo["BoundingBox"]["Top"] +
                (faceInfo["BoundingBox"]["Height"] * 2) / 3,
              left: faceInfo["BoundingBox"]["Left"],
            },
            rotation: {
              xy: faceInfo["Pose"]["Yaw"],
              yz: faceInfo["Pose"]["Roll"],
              zx: faceInfo["Pose"]["Pitch"],
            },
          };

          resolve(result);
        });
      });
    }

    // Image를 선택하는 Input의 ID를 파라미터로 입력.
    async function ProcessImage(fileInputId) {
      const control = document.getElementById(fileInputId);
      const file = control.files[0];

      // Load base64 encoded image
      const reader = new FileReader();
      reader.onload = (function (theFile) {
        return async function (e) {
          console.log(e.target)
          let image = null;
          let jpg = true;
          try {
            image = atob(e.target.result.split("data:image/jpeg;base64,")[1]);
          } catch (e) {
            jpg = false;
          }
          if (jpg == false) {
            try {
              image = atob(e.target.result.split("data:image/png;base64,")[1]);
            } catch (e) {
              alert("Not an image file Rekognition can process");
              return;
            }
          }
          //unencode image bytes for Rekognition DetectFaces API
          const length = image.length;
          imageBytes = new ArrayBuffer(length);
          const ua = new Uint8Array(imageBytes);
          for (let i = 0; i < length; i++) {
            ua[i] = image.charCodeAt(i);
          }
          //Call Rekognition
          const faceInfo = await getFaceInfo(imageBytes);

          // 여기서 DOM 조작
        };
      })(file);
      reader.readAsDataURL(file);
    }
  </script>
</html>

